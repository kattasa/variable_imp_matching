{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/project/xtmp/sk787/variable_imp_matching/')\n",
    "sys.path.insert(0, '/usr/project/xtmp/sk787/variable_imp_matching/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsRegressor\n",
    "from datagen.dgp_df import dgp_df\n",
    "\n",
    "from confseq.betting import betting_ci\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Experiments.variance.randomization_coverage_exp import knn_match\n",
    "from datagen.dgp import dgp_linear, dgp_lihua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['Experiments.variance.randomization_coverage_exp'])\n",
    "from Experiments.variance.randomization_coverage_exp import knn_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1000\n",
    "n_est = 5000\n",
    "n_query = 500\n",
    "train_query_seed = 42\n",
    "xmin = -5\n",
    "xmax = 5\n",
    "n_imp = 2\n",
    "n_unimp = 0\n",
    "heteroskedastic = 0\n",
    "corr = False\n",
    "\n",
    "k = 16 * int(np.sqrt(n_est))\n",
    "\n",
    "gen_linear_dgp = dgp_lihua(xmin = xmin, xmax = xmax, n_imp = n_imp, n_unimp=n_unimp, heteroskedastic=heteroskedastic, corr = corr)\n",
    "\n",
    "np.random.seed(train_query_seed)\n",
    "X_train, train_df, train_true_df, X_est, est_df, est_true_df, X_query, query_df, query_true_df = gen_linear_dgp.gen_train_est_query(n_train = n_train, n_est = n_est, n_query = n_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1\n",
    "confint_df_list = []\n",
    "for iter in range(n_iter):\n",
    "    print(iter)\n",
    "    seed = 42 * iter\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ## resample X and T\n",
    "    df_iter, df_true_iter = gen_linear_dgp.gen_resampled_dataset(X_est)\n",
    "\n",
    "    X_est_iter = X_est.copy()\n",
    "    T_est_iter = df_iter['T'].values\n",
    "    Y_est_iter = df_iter['Y'].values\n",
    "\n",
    "    ## estimate confidence intervals on this iteration\n",
    "    knn_match_iter = knn_match(prop_score = gen_linear_dgp.prop_score, outcome_reg = gen_linear_dgp.outcome_reg, ymin = gen_linear_dgp.ymin, ymax = gen_linear_dgp.ymax)\n",
    "    knn_match_iter.learn_projection(X_train, train_df['T'].values, train_df['Y'].values, algorithm = 'true_coef', args = {'coef' : np.array([1,1])})# args = {'coef' : gen_linear_dgp.coef})\n",
    "    # knn_match_iter.learn_projection(X_train, train_df['T'].values, train_df['Y'].values, algorithm = 'true_prog')\n",
    "    knn_match_iter.fit(X_est_iter, T_est_iter, Y_est_iter, k = k)\n",
    "\n",
    "    lb_iter, ub_iter, bias_iter = knn_match_iter.est_cate_conf_int(X_query, alpha = 0.05, return_bias = True)\n",
    "    cate_mg = knn_match_iter.est_cate_mg_or(X_query)\n",
    "    cate_est = knn_match_iter.est_cate(X_query)\n",
    "\n",
    "    true_df_iter = query_true_df.copy()\n",
    "    true_df_iter['lb'] = lb_iter\n",
    "    true_df_iter['ub'] = ub_iter\n",
    "    true_df_iter['bias'] = bias_iter\n",
    "    true_df_iter['seed'] = seed\n",
    "    true_df_iter['cate_mg'] = cate_mg\n",
    "    true_df_iter['cate_est'] = cate_est\n",
    "\n",
    "    confint_df_list.append(true_df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = knn_match_iter.find_nn(X_query)\n",
    "# # get treatment and outcome of nearest neighbors\n",
    "# mu_nn_T = knn_match_iter.mu_x_T[indices].mean(axis = 1)\n",
    "# mu_nn_C = knn_match_iter.mu_x_C[indices].mean(axis = 1)\n",
    "cate_or = (knn_match_iter.outcome_reg(X_query, T = 1) - knn_match_iter.outcome_reg(X_query, T = 0)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((true_df_iter['cate_true'] - true_df_iter['cate_est'])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## why is the interval width so tight for SAVI?\n",
    "## the width for normal approx is 0.03... but the width for SAVI is 0.023...\n",
    "pd.concat([x.assign(id = range(x.shape[0])).assign(coverage = lambda x: (x.lb <= x.cate_true) * (x.cate_true <= x.ub)).assign(length = lambda x: (x.ub - x.lb)/(gen_linear_dgp.ymax - gen_linear_dgp.ymin)) for x in confint_df_list], axis = 0).groupby('id')[['coverage', 'length']].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confint_df_full = pd.concat([x.assign(id = range(x.shape[0])).assign(coverage = lambda x: (x.lb <= x.cate_true) * (x.cate_true <= x.ub)).assign(length = lambda x: (x.ub - x.lb)/(gen_linear_dgp.ymax - gen_linear_dgp.ymin)) for x in confint_df_list], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "x_gb_df = confint_df_full.groupby('id')[['X_0', 'X_1', 'T', 'coverage', 'length']].mean()\n",
    "sns.scatterplot(x = 'X_0', y = 'X_1', hue = (gen_linear_dgp.prop_score(df_iter.drop(['Y', 'T'], axis = 1))).flatten(), data = df_iter)\n",
    "plt.title('Propensity score')\n",
    "plt.show()\n",
    "sns.scatterplot(x = 'X_0', y = 'X_1', hue = 'coverage', data = x_gb_df)\n",
    "plt.show()\n",
    "sns.scatterplot(x = 'X_0', y = 'X_1', hue = (gen_linear_dgp.outcome_reg(df_iter.drop(['Y', 'T'], axis = 1), T = 1) - gen_linear_dgp.outcome_reg(df_iter.drop(['Y', 'T'], axis = 1), T = 0)).flatten(), data = df_iter)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "indices = knn_match_iter.nbrs.kneighbors(X_query, return_distance = False)\n",
    "query_point = X_query.index[20]\n",
    "nn_idxs = indices[query_point, ]\n",
    "# Extract the points that meet the condition\n",
    "df_iter['in_mg'] = 0\n",
    "df_iter.loc[nn_idxs, 'in_mg'] = 1\n",
    "points = df_iter.loc[nn_idxs, ['X_0', 'X_1']].values\n",
    "\n",
    "# Compute the convex hull\n",
    "hull = ConvexHull(points)\n",
    "\n",
    "# Plot the points\n",
    "sns.scatterplot(x='X_0', y='X_1', hue = 'in_mg', data=df_iter)\n",
    "\n",
    "# Plot the convex hull\n",
    "for simplex in hull.simplices:\n",
    "    plt.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
    "star = X_query.loc[query_point, ['X_0', 'X_1']].values\n",
    "plt.plot(star[0], star[1], 'ro', markersize = 18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confint_df_full['lb_wo_bias'] = confint_df_full['lb'] - confint_df_full['bias']\n",
    "confint_df_full['ub_wo_bias'] = confint_df_full['ub'] - confint_df_full['bias']\n",
    "\n",
    "confint_df_full['lb_w_2bias'] = confint_df_full['lb'] + confint_df_full['bias']\n",
    "confint_df_full['ub_w_2bias'] = confint_df_full['ub'] + confint_df_full['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length = 0.27\n",
    "# length = 0.625\n",
    "confint_df_full['coverage_wo_bias'] = (confint_df_full['lb_wo_bias'] <= confint_df_full['cate_true']) * (confint_df_full['cate_true'] <= confint_df_full['ub_wo_bias'])\n",
    "confint_df_full['interval_width_wo_bias'] = confint_df_full['ub_wo_bias'] - confint_df_full['lb_wo_bias']\n",
    "\n",
    "confint_df_full['coverage_mg_wo_bias'] = (confint_df_full['lb_wo_bias'] <= confint_df_full['cate_mg']) * (confint_df_full['cate_mg'] <= confint_df_full['ub_wo_bias'])\n",
    "confint_df_full['interval_width_mg_wo_bias'] = confint_df_full['ub_wo_bias'] - confint_df_full['lb_wo_bias']\n",
    "\n",
    "confint_df_full['coverage_w_bias'] = (confint_df_full['lb'] <= confint_df_full['cate_true']) * (confint_df_full['cate_true'] <= confint_df_full['ub'])\n",
    "confint_df_full['interval_width_w_bias'] = confint_df_full['ub'] - confint_df_full['lb']\n",
    "\n",
    "confint_df_full['coverage_mg_w_bias'] = (confint_df_full['lb'] <= confint_df_full['cate_mg']) * (confint_df_full['cate_mg'] <= confint_df_full['ub'])\n",
    "confint_df_full['interval_width_mg_w_bias'] = confint_df_full['ub'] - confint_df_full['lb']\n",
    "\n",
    "confint_df_full['coverage_w_2bias'] = (confint_df_full['lb_w_2bias'] <= confint_df_full['cate_true']) * (confint_df_full['cate_true'] <= confint_df_full['ub_w_2bias'])\n",
    "confint_df_full['interval_width_w_2bias'] = confint_df_full['ub_w_2bias'] - confint_df_full['lb_w_2bias']\n",
    "\n",
    "confint_df_full['coverage_mg_w_2bias'] = (confint_df_full['lb_w_2bias'] <= confint_df_full['cate_mg']) * (confint_df_full['cate_mg'] <= confint_df_full['ub_w_2bias'])\n",
    "confint_df_full['interval_width_mg_w_2bias'] = confint_df_full['ub_w_2bias'] - confint_df_full['lb_w_2bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confint_df_full.groupby('id')[['coverage_wo_bias', 'coverage_w_bias', 'coverage_w_2bias', 'coverage_mg_wo_bias', 'coverage_mg_w_bias', 'coverage_mg_w_2bias']].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1000\n",
    "n_est = 1000\n",
    "n_query = 100\n",
    "train_query_seed = 42\n",
    "xmin = -5\n",
    "xmax = 2\n",
    "n_imp = 5\n",
    "n_unimp = 0\n",
    "heteroskedastic = 0\n",
    "\n",
    "k = 2 * int(np.sqrt(n_est))\n",
    "\n",
    "# gen_linear_dgp = dgp_lihua(xmin = xmin, xmax = xmax, n_imp = n_imp, n_unimp=n_unimp, heteroskedastic=heteroskedastic, corr = False)\n",
    "gen_linear_dgp = dgp_linear(xmin = xmin, xmax = xmax, n_imp = n_imp, n_unimp = n_unimp, heteroskedastic=heteroskedastic)\n",
    "\n",
    "np.random.seed(train_query_seed)\n",
    "X_train, train_df, train_true_df, X_est, est_df, est_true_df, X_query, query_df, query_true_df = gen_linear_dgp.gen_train_est_query(n_train = n_train, n_est = n_est, n_query = n_query)\n",
    "T_train = train_df['T'].values\n",
    "Y_train = train_df['Y'].values\n",
    "\n",
    "confint_df_list = []\n",
    "for k_constant in range(1, 20, 3):\n",
    "    print(k_constant)\n",
    "    k = k_constant * int(np.sqrt(n_est))\n",
    "    if k > n_est:\n",
    "        k = n_est\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ## resample X and T\n",
    "    df_iter, df_true_iter = gen_linear_dgp.gen_resampled_dataset(X_est)\n",
    "\n",
    "    X_est_iter = X_est.copy()\n",
    "    T_est_iter = df_iter['T'].values\n",
    "    Y_est_iter = df_iter['Y'].values\n",
    "\n",
    "    ## estimate confidence intervals on this iteration\n",
    "    class or_class:\n",
    "        def __init__(self, or_estimator, or_args = {}):\n",
    "            self.or_T = or_estimator(**or_args)\n",
    "            self.or_C = or_estimator(**or_args)\n",
    "        def fit(self, X_train, T_train, Y_train):\n",
    "            X_train = np.array(X_train)\n",
    "            self.or_T.fit(X_train[T_train == 1, ], Y_train[T_train == 1])\n",
    "            self.or_C.fit(X_train[T_train == 0, ], Y_train[T_train == 0])\n",
    "        def predict(self, X_query, T):\n",
    "            if T == 1:\n",
    "                return self.or_T.predict(X_query).reshape(-1,1)\n",
    "            elif T == 0:\n",
    "                return self.or_C.predict(X_query).reshape(-1,1)\n",
    "            else:\n",
    "                raise ValueError('T must be 0/1. Uncrecognized T:', T)\n",
    "        \n",
    "    outcome_reg = or_class(RandomForestRegressor)\n",
    "    outcome_reg.fit(X_train, T_train, Y_train)\n",
    "\n",
    "    # prop_score None defaults to using NNs...\n",
    "    knn_match_iter = knn_match(prop_score = None, outcome_reg = outcome_reg.predict, ymin = gen_linear_dgp.ymin, ymax = gen_linear_dgp.ymax, bias_correction = True)\n",
    "\n",
    "    ## fit projection on training set\n",
    "    knn_match_iter.learn_projection(X_train, T_train, Y_train, algorithm = 'rf_prognostic_score')\n",
    "\n",
    "    ## estimate intervals on estimation set\n",
    "    knn_match_iter.fit(X_est_iter, T_est_iter, Y_est_iter, k = k)\n",
    "\n",
    "    lb_iter, ub_iter = knn_match_iter.est_cate_conf_int(X_query, alpha = 0.05)\n",
    "\n",
    "\n",
    "    # knn_match_iter = knn_match(prop_score = gen_linear_dgp.prop_score, outcome_reg = gen_linear_dgp.outcome_reg, ymin = gen_linear_dgp.ymin, ymax = gen_linear_dgp.ymax)\n",
    "    # knn_match_iter = knn_match(prop_score = None, outcome_reg = lambda X, T: np.zeros((X.shape[0], 1)), ymin = gen_linear_dgp.ymin, ymax = gen_linear_dgp.ymax)\n",
    "    # knn_match_iter.learn_projection(X_train, train_df['T'].values, train_df['Y'].values, algorithm = 'true_coef', args = {'coef' : gen_linear_dgp.coef})\n",
    "    # knn_match_iter.fit(X_est_iter, T_est_iter, Y_est_iter, k = k)\n",
    "\n",
    "    # lb_iter, ub_iter = knn_match_iter.est_cate_conf_int(X_query, alpha = 0.05)\n",
    "\n",
    "    true_df_iter = query_true_df.copy()\n",
    "    true_df_iter['lb'] = lb_iter\n",
    "    true_df_iter['ub'] = ub_iter\n",
    "    true_df_iter['seed'] = seed\n",
    "    true_df_iter['k'] = k\n",
    "\n",
    "    confint_df_list.append(true_df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([x.assign(id = range(x.shape[0])).assign(coverage = lambda x: (x.lb <= x.cate_true) * (x.cate_true <= x.ub)).assign(length = lambda x: (x.ub - x.lb)/(gen_linear_dgp.ymax - gen_linear_dgp.ymin)) for x in confint_df_list], axis = 0).groupby(['id', 'k'])[['coverage', 'length']].mean().reset_index().groupby('k')[['coverage', 'length']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPW ATE Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1000\n",
    "n_est = 50000\n",
    "n_query = 1\n",
    "train_query_seed = 42\n",
    "xmin = -5\n",
    "xmax = 5\n",
    "n_imp = 2\n",
    "n_unimp = 0\n",
    "heteroskedastic = 0\n",
    "corr = False\n",
    "\n",
    "k = n_est\n",
    "\n",
    "gen_linear_dgp = dgp_lihua(xmin = xmin, xmax = xmax, n_imp = n_imp, n_unimp=n_unimp, heteroskedastic=heteroskedastic, corr = corr)\n",
    "\n",
    "np.random.seed(train_query_seed)\n",
    "X_train, train_df, train_true_df, X_est, est_df, est_true_df, X_query, query_df, query_true_df = gen_linear_dgp.gen_train_est_query(n_train = n_train, n_est = n_est, n_query = n_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.]\n",
      "1\n",
      "[0.]\n",
      "2\n",
      "[0.]\n",
      "3\n",
      "[0.]\n",
      "4\n",
      "[0.]\n",
      "5\n",
      "[0.]\n",
      "6\n",
      "[0.]\n",
      "7\n",
      "[0.]\n",
      "8\n",
      "[0.]\n",
      "9\n",
      "[0.]\n",
      "10\n",
      "[0.]\n",
      "11\n",
      "[0.]\n",
      "12\n",
      "[0.]\n",
      "13\n",
      "[0.]\n",
      "14\n",
      "[0.]\n",
      "15\n",
      "[0.]\n",
      "16\n",
      "[0.]\n",
      "17\n",
      "[0.]\n",
      "18\n",
      "[0.]\n",
      "19\n",
      "[0.]\n",
      "20\n",
      "[0.]\n",
      "21\n",
      "[0.]\n",
      "22\n",
      "[0.]\n",
      "23\n",
      "[0.]\n",
      "24\n",
      "[0.]\n",
      "25\n",
      "[0.]\n",
      "26\n",
      "[0.]\n",
      "27\n",
      "[0.]\n",
      "28\n",
      "[0.]\n",
      "29\n",
      "[0.]\n",
      "30\n",
      "[0.]\n",
      "31\n",
      "[0.]\n",
      "32\n",
      "[0.]\n",
      "33\n",
      "[0.]\n",
      "34\n",
      "[0.]\n",
      "35\n",
      "[0.]\n",
      "36\n",
      "[0.]\n",
      "37\n",
      "[0.]\n",
      "38\n",
      "[0.]\n",
      "39\n",
      "[0.]\n",
      "40\n",
      "[0.]\n",
      "41\n",
      "[0.]\n",
      "42\n",
      "[0.]\n",
      "43\n",
      "[0.]\n",
      "44\n",
      "[0.]\n",
      "45\n",
      "[0.]\n",
      "46\n",
      "[0.]\n",
      "47\n",
      "[0.]\n",
      "48\n",
      "[0.]\n",
      "49\n",
      "[0.]\n",
      "50\n",
      "[0.]\n",
      "51\n",
      "[0.]\n",
      "52\n",
      "[0.]\n",
      "53\n",
      "[0.]\n",
      "54\n",
      "[0.]\n",
      "55\n",
      "[0.]\n",
      "56\n",
      "[0.]\n",
      "57\n",
      "[0.]\n",
      "58\n",
      "[0.]\n",
      "59\n",
      "[0.]\n",
      "60\n",
      "[0.]\n",
      "61\n",
      "[0.]\n",
      "62\n",
      "[0.]\n",
      "63\n",
      "[0.]\n",
      "64\n",
      "[0.]\n",
      "65\n",
      "[0.]\n",
      "66\n",
      "[0.]\n",
      "67\n",
      "[0.]\n",
      "68\n",
      "[0.]\n",
      "69\n",
      "[0.]\n",
      "70\n",
      "[0.]\n",
      "71\n",
      "[0.]\n",
      "72\n",
      "[0.]\n",
      "73\n",
      "[0.]\n",
      "74\n",
      "[0.]\n",
      "75\n",
      "[0.]\n",
      "76\n",
      "[0.]\n",
      "77\n",
      "[0.]\n",
      "78\n",
      "[0.]\n",
      "79\n",
      "[0.]\n",
      "80\n",
      "[0.]\n",
      "81\n",
      "[0.]\n",
      "82\n",
      "[0.]\n",
      "83\n",
      "[0.]\n",
      "84\n",
      "[0.]\n",
      "85\n",
      "[0.]\n",
      "86\n",
      "[0.]\n",
      "87\n",
      "[0.]\n",
      "88\n",
      "[0.]\n",
      "89\n",
      "[0.]\n",
      "90\n",
      "[0.]\n",
      "91\n",
      "[0.]\n",
      "92\n",
      "[0.]\n",
      "93\n",
      "[0.]\n",
      "94\n",
      "[0.]\n",
      "95\n",
      "[0.]\n",
      "96\n",
      "[0.]\n",
      "97\n",
      "[0.]\n",
      "98\n",
      "[0.]\n",
      "99\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "n_iter = 100\n",
    "confint_list = []\n",
    "coverage = 0\n",
    "for iter in range(n_iter):\n",
    "    print(iter)\n",
    "    seed = 42 * iter\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ## resample X and T\n",
    "    df_iter, df_true_iter = gen_linear_dgp.gen_resampled_dataset(X_est)\n",
    "\n",
    "    X_est_iter = X_est.copy()\n",
    "    T_est_iter = df_iter['T'].values\n",
    "    Y_est_iter = df_iter['Y'].values\n",
    "\n",
    "    ## estimate confidence intervals on this iteration\n",
    "    knn_match_iter = knn_match(prop_score = gen_linear_dgp.prop_score, outcome_reg = lambda X, T : np.zeros(X.shape[0]), ymin = gen_linear_dgp.ymin, ymax = gen_linear_dgp.ymax)\n",
    "    knn_match_iter.learn_projection(X_train, train_df['T'].values, train_df['Y'].values, algorithm = 'true_coef', args = {'coef' : np.array([1,1])})# args = {'coef' : gen_linear_dgp.coef})\n",
    "    # knn_match_iter.learn_projection(X_train, train_df['T'].values, train_df['Y'].values, algorithm = 'true_prog')\n",
    "    knn_match_iter.fit(X_est_iter, T_est_iter, Y_est_iter, k = k)\n",
    "\n",
    "    lb_iter, ub_iter, bias_iter = knn_match_iter.est_cate_conf_int(X_query, alpha = 0.05, return_bias = True)\n",
    "    lb_iter = lb_iter - bias_iter\n",
    "    ub_iter = ub_iter - bias_iter\n",
    "\n",
    "    cate_mg = knn_match_iter.est_cate_mg_or(X_query)\n",
    "    cate_est = knn_match_iter.est_cate(X_query)\n",
    "\n",
    "    ate_true = (gen_linear_dgp.outcome_reg(X_est, T = 1) - gen_linear_dgp.outcome_reg(X_est, T = 0)).mean()\n",
    "\n",
    "    coverage += (lb_iter <= ate_true) * (ate_true <= ub_iter)\n",
    "    print('bias', bias_iter)\n",
    "    print('coverage', coverage/(iter + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb_iter[0], ub_iter[0]\n",
    "bias_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
